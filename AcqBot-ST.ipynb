{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3800ca3-2bf4-485e-bd0f-5df25a311703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (1.51.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow<22,>=7.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: hf_xet in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Collecting optimum-intel@ git+https://github.com/huggingface/optimum-intel.git (from optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/optimum-intel.git 'C:\\Users\\pwdev\\AppData\\Local\\Temp\\pip-install-25qrfcai\\optimum-intel_c2fc25063191479e93c4e0a5edd0a483'\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/optimum-onnx.git 'C:\\Users\\pwdev\\AppData\\Local\\Temp\\pip-install-25qrfcai\\optimum-onnx_523b8f1fc33840ef94f4076638c2ed71'\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/optimum 'C:\\Users\\pwdev\\AppData\\Local\\Temp\\pip-install-25qrfcai\\optimum_6cdb3a5aec0d4f4483ef392741adb684'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/huggingface/optimum-intel.git to c:\\users\\pwdev\\appdata\\local\\temp\\pip-install-25qrfcai\\optimum-intel_c2fc25063191479e93c4e0a5edd0a483\n",
      "  Resolved https://github.com/huggingface/optimum-intel.git to commit 25fcb63a9ab9825a41ebaa84852ab18f30a61d31\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting optimum-onnx@ git+https://github.com/huggingface/optimum-onnx.git@main (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Cloning https://github.com/huggingface/optimum-onnx.git (to revision main) to c:\\users\\pwdev\\appdata\\local\\temp\\pip-install-25qrfcai\\optimum-onnx_523b8f1fc33840ef94f4076638c2ed71\n",
      "  Resolved https://github.com/huggingface/optimum-onnx.git to commit 682988bc2fd972f4594fb66725fa7e7c6c2b628d\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch>=2.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.7.1)\n",
      "Requirement already satisfied: transformers<4.58,>=4.45 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.57.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (80.9.0)\n",
      "Requirement already satisfied: nncf>=2.19.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.19.0)\n",
      "Requirement already satisfied: openvino>=2025.4.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2025.4.1)\n",
      "Requirement already satisfied: openvino-tokenizers>=2025.4.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2025.4.1.0)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.23.0)\n",
      "Requirement already satisfied: natsort>=7.1.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (8.4.0)\n",
      "Requirement already satisfied: networkx<3.5.0,>=2.6 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.3)\n",
      "Requirement already satisfied: ninja<1.14,>=1.10.0.post2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.13.0)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.24.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.26.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (24.2)\n",
      "Requirement already satisfied: pandas<2.4,>=1.1.5 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.3.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (5.9.0)\n",
      "Requirement already satisfied: pydot<=3.0.4,>=1.4.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.0.4)\n",
      "Requirement already satisfied: pymoo>=0.6.0.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.6.1.6)\n",
      "Requirement already satisfied: rich>=13.5.2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (13.7.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.13.1)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.66.5)\n",
      "Collecting optimum@ git+https://github.com/huggingface/optimum (from optimum-onnx@ git+https://github.com/huggingface/optimum-onnx.git@main->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git)\n",
      "  Cloning https://github.com/huggingface/optimum to c:\\users\\pwdev\\appdata\\local\\temp\\pip-install-25qrfcai\\optimum_6cdb3a5aec0d4f4483ef392741adb684\n",
      "  Resolved https://github.com/huggingface/optimum to commit 6cfe1ee69f8f4e6380f613961b3a8b228e257539\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: onnx in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from optimum-onnx@ git+https://github.com/huggingface/optimum-onnx.git@main->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.18.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pandas<2.4,>=1.1.5->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pandas<2.4,>=1.1.5->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pandas<2.4,>=1.1.5->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2023.3)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pydot<=3.0.4,>=1.4.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.1.2)\n",
      "Requirement already satisfied: moocore>=0.1.7 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.1.10)\n",
      "Requirement already satisfied: autograd>=1.4 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.8.0)\n",
      "Requirement already satisfied: cma>=3.2.2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.4.1)\n",
      "Requirement already satisfied: matplotlib>=3 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.9.2)\n",
      "Requirement already satisfied: alive_progress in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.3.0)\n",
      "Requirement already satisfied: Deprecated in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.2.18)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from rich>=13.5.2->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from rich>=13.5.2->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.0->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24.0->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from jinja2->torch>=2.1->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from onnx->optimum-onnx@ git+https://github.com/huggingface/optimum-onnx.git@main->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (5.29.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests->transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests->transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests->transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from requests->transformers<4.58,>=4.45->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2025.10.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (11.1.0)\n",
      "Requirement already satisfied: cffi>=1.17.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from moocore>=0.1.7->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.17.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from moocore>=0.1.7->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.4,>=1.1.5->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.16.0)\n",
      "Requirement already satisfied: about-time==4.2.1 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from alive_progress->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (4.2.1)\n",
      "Requirement already satisfied: graphemeu==0.7.2 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from alive_progress->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (0.7.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from Deprecated->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (1.14.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\pwdev\\anaconda3\\lib\\site-packages (from cffi>=1.17.1->moocore>=0.1.7->pymoo>=0.6.0.1->nncf>=2.19.0->optimum-intel@ git+https://github.com/huggingface/optimum-intel.git->optimum-intel[openvino]@ git+https://github.com/huggingface/optimum-intel.git) (2.21)\n",
      "Building wheels for collected packages: optimum-intel, optimum-onnx, optimum\n",
      "  Building wheel for optimum-intel (pyproject.toml): started\n",
      "  Building wheel for optimum-intel (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for optimum-intel: filename=optimum_intel-1.27.0.dev0+25fcb63-py3-none-any.whl size=374094 sha256=17b900060b92df64a6941e7190172cd2bcd2cbd453aca903dfb6134d070036b8\n",
      "  Stored in directory: C:\\Users\\pwdev\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-huz5ucd2\\wheels\\3e\\28\\37\\922d7ce51fa59781a14b4187a13184af5a1d19da8b80d59adb\n",
      "  Building wheel for optimum-onnx (pyproject.toml): started\n",
      "  Building wheel for optimum-onnx (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for optimum-onnx: filename=optimum_onnx-0.1.0.dev0-py3-none-any.whl size=195271 sha256=ef6cac0623a824e0cedae2088910458365f33051bbe2b9f93aee03cb16f826e0\n",
      "  Stored in directory: C:\\Users\\pwdev\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-huz5ucd2\\wheels\\f0\\bb\\0e\\8f13d46f850db0748ed4f8c61e63666f191289611d43a93dc0\n",
      "  Building wheel for optimum (pyproject.toml): started\n",
      "  Building wheel for optimum (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for optimum: filename=optimum-2.1.0.dev0-py3-none-any.whl size=162382 sha256=224c6684e0daec51bcb15400c7bc8dde04faace9f7dbae5ef279cbd692a247d0\n",
      "  Stored in directory: C:\\Users\\pwdev\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-huz5ucd2\\wheels\\4a\\c7\\72\\f0a71f75076bac382ef01cf2f8ae694d709b39641555fd36e0\n",
      "Successfully built optimum-intel optimum-onnx optimum\n",
      "Installing collected packages: optimum, optimum-onnx, optimum-intel\n",
      "  Attempting uninstall: optimum\n",
      "    Found existing installation: optimum 2.1.0\n",
      "    Uninstalling optimum-2.1.0:\n",
      "      Successfully uninstalled optimum-2.1.0\n",
      "  Attempting uninstall: optimum-onnx\n",
      "    Found existing installation: optimum-onnx 0.1.0\n",
      "    Uninstalling optimum-onnx-0.1.0:\n",
      "      Successfully uninstalled optimum-onnx-0.1.0\n",
      "  Attempting uninstall: optimum-intel\n",
      "    Found existing installation: optimum-intel 1.27.0\n",
      "    Uninstalling optimum-intel-1.27.0:\n",
      "      Successfully uninstalled optimum-intel-1.27.0\n",
      "Successfully installed optimum-2.1.0.dev0 optimum-intel-1.27.0.dev0+25fcb63 optimum-onnx-0.1.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "!pip install hf_xet\n",
    "!pip install \"optimum-intel[openvino]\"@git+https://github.com/huggingface/optimum-intel.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97dc0687-3dfc-4a21-b7b7-a02cf49ec629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit_app.py - Lightweight deployment version\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import chromadb\n",
    "from optimum.intel.openvino import OVModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e1fc03-e001-46f3-8d1f-5f2a60d00e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 20:44:10.469 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:44:11.222 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2026-01-03 20:44:11.224 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:44:11.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:44:11.234 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:44:11.741 Thread 'Thread-27': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:44:11.757 Thread 'Thread-27': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:44:11.760 Thread 'Thread-27': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54cf14840f74c19bcacbbd381a90322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/736 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pwdev\\.cache\\huggingface\\hub\\models--microsoft--phi-1_5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1752a4c49cdb4480b41d73858a86178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7c449195cd47c0bc7176174a43de2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37375314cc12481f986905d40f6c8b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce74d8f8f8bd4cedb90093ac13278433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5783edfd9117409a90f153d5437d482d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e798e9e5cc864f16aa860270f8a9a427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4284b5112d3141f5bcc20539002f2a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86033a3e101455388d6d7809e703d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\transformers\\cache_utils.py:132: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not self.is_initialized or self.keys.numel() == 0:\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\transformers\\masking_utils.py:207: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (padding_length := kv_length + kv_offset - attention_mask.shape[-1]) > 0:\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\optimum\\exporters\\openvino\\model_patcher.py:207: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(0.0, device=mask.device, dtype=dtype),\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\optimum\\exporters\\openvino\\model_patcher.py:208: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(torch.finfo(torch.float16).min, device=mask.device, dtype=dtype),\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:81: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  is_causal = query.shape[2] > 1 and attention_mask is None and getattr(module, \"is_causal\", True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:nncf:NNCF provides best results with torch==2.9.*, while current torch version is 2.7.1+cpu. If you encounter issues, consider switching to torch==2.9.*\n",
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+---------------------------+-----------------------------+----------------------------------------+\n",
      "| Weight compression mode   | % all parameters (layers)   | % ratio-defining parameters (layers)   |\n",
      "+===========================+=============================+========================================+\n",
      "| int8_asym, per-channel    | 100% (146 / 146)            | 100% (146 / 146)                       |\n",
      "+---------------------------+-----------------------------+----------------------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a68bdf634b4c04a489eea0c7134c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2026-01-03 20:48:10.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.232 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Caching prevents the model from reloading on every interaction\n",
    "@st.cache_resource\n",
    "def load_optimized_model(model_id=\"microsoft/phi-1_5\"):\n",
    "    # Export and load with OpenVINO for CPU acceleration\n",
    "    model = OVModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        export=True, \n",
    "        compile=True, \n",
    "        device=\"CPU\"\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    return pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "llm_pipeline = load_optimized_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e78f619-b6ad-49bb-a974-353e61bbee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_resource\n",
    "def load_rag_resources():\n",
    "    \"\"\"Load the model, tokenizer, and persistent DB client once.\"\"\"\n",
    "    model_id = \"microsoft/phi-1.5\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    model = OVModelForCausalLM.from_pretrained(\n",
    "        model_id, \n",
    "        export=True, \n",
    "        compile=True, \n",
    "        device=\"CPU\",\n",
    "        device_map=\"auto\", \n",
    "        torch_dtype=torch.float16, \n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    gen_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "    client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "    collection = client.get_collection(name=\"RAG_Assistant\")\n",
    "    \n",
    "    return gen_pipeline, collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df6fe9d-d2aa-40f7-b08d-5619dc522157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, context, gen_pipeline):\n",
    "    \"\"\"Phi-1.5 specific prompt formatting\"\"\"\n",
    "    prompt = (\n",
    "        f\"Instruct: Answer the question based on the provided federal documents.\\n\"\n",
    "        f\"Context: {context}\\n\"\n",
    "        f\"Question: {query}\\n\"\n",
    "        f\"Output:\"\n",
    "    )\n",
    "    results = gen_pipeline(prompt, max_new_tokens=300, temperature=0.1, return_full_text=False)\n",
    "    return results[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e424ef2b-5529-4600-872e-4b0729b90d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 20:48:10.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.338 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.343 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.347 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.350 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.363 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:10.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:11.036 Thread 'Thread-51': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:11.042 Thread 'Thread-52': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:11.044 Thread 'Thread-51': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:11.050 Thread 'Thread-52': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:11.059 Thread 'Thread-51': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:48:11.061 Thread 'Thread-52': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "Model type `phi` export for task `text-generation-with-past` is not supported for loading with `trust_remote_code=True`using default export configuration, `trust_remote_code` will be disabled. Please provide custom export config if you want load model with remote code.\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\transformers\\cache_utils.py:132: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not self.is_initialized or self.keys.numel() == 0:\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\transformers\\masking_utils.py:207: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (padding_length := kv_length + kv_offset - attention_mask.shape[-1]) > 0:\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\optimum\\exporters\\openvino\\model_patcher.py:207: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(0.0, device=mask.device, dtype=dtype),\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\optimum\\exporters\\openvino\\model_patcher.py:208: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(torch.finfo(torch.float16).min, device=mask.device, dtype=dtype),\n",
      "C:\\Users\\pwdev\\anaconda3\\Lib\\site-packages\\transformers\\integrations\\sdpa_attention.py:81: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  is_causal = query.shape[2] > 1 and attention_mask is None and getattr(module, \"is_causal\", True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Statistics of the bitwidth distribution:\n",
      "+---------------------------+-----------------------------+----------------------------------------+\n",
      "| Weight compression mode   | % all parameters (layers)   | % ratio-defining parameters (layers)   |\n",
      "+===========================+=============================+========================================+\n",
      "| int8_asym, per-channel    | 100% (146 / 146)            | 100% (146 / 146)                       |\n",
      "+---------------------------+-----------------------------+----------------------------------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da36fd52784fb4ad48eab83f91b0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "2026-01-03 20:49:58.594 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.595 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.596 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.597 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.598 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.599 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.600 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.601 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.602 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.604 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.605 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.606 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.607 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.612 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.617 Session state does not function when running a script without `streamlit run`\n",
      "2026-01-03 20:49:58.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.624 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-01-03 20:49:58.629 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    st.set_page_config(page_title=\"FedAcq Chatbot\", layout=\"wide\")\n",
    "    st.title(\"FedAcq Chatbot App\")\n",
    "    st.markdown(\"Query federal acquisition policies using RAG with Phi-1.5.\")\n",
    "\n",
    "    # Load resources\n",
    "    with st.spinner(\"Initializing models and database...\"):\n",
    "        gen_pipeline, collection = load_rag_resources()\n",
    "\n",
    "    # Sidebar Configuration\n",
    "    st.sidebar.title(\"Search Settings\")\n",
    "    n_results = st.sidebar.slider(\"Context Documents\", 1, 5, 3)\n",
    "\n",
    "    # User Input\n",
    "    user_question = st.text_area(\n",
    "        \"Ask a question about federal acquisition policies:\", \n",
    "        placeholder=\"e.g., What are the requirements for small business set-asides?\"\n",
    "    )\n",
    "\n",
    "    if st.button(\"Get Answer\"):\n",
    "        if not user_question:\n",
    "            st.warning(\"Please enter a question.\")\n",
    "            return\n",
    "\n",
    "        with st.spinner(\"Retrieving documents and generating response...\"):\n",
    "            # A. Search ChromaDB\n",
    "            # (Note: ChromaDB uses its default embedding function to handle query_texts)\n",
    "            results = collection.query(\n",
    "                query_texts=[user_question], \n",
    "                n_results=n_results\n",
    "            )\n",
    "\n",
    "            # B. Format Context\n",
    "            retrieved_docs = results[\"documents\"][0]\n",
    "            retrieved_metas = results[\"metadatas\"][0]\n",
    "            \n",
    "            context_segments = []\n",
    "            for i, (doc, meta) in enumerate(zip(retrieved_docs, retrieved_metas)):\n",
    "                source = meta.get('title', 'Unknown Source')\n",
    "                context_segments.append(f\"[Doc {i+1} - {source}]: {doc}\")\n",
    "            \n",
    "            full_context = \"\\n\\n\".join(context_segments)\n",
    "\n",
    "            # C. Generate Answer\n",
    "            answer = generate_answer(user_question, full_context, gen_pipeline)\n",
    "\n",
    "            # D. Display Results\n",
    "            st.subheader(\"Answer\")\n",
    "            st.write(answer)\n",
    "\n",
    "            # E. Sources Expander\n",
    "            with st.expander(\"View Source Documents\"):\n",
    "                for i, (doc, meta) in enumerate(zip(retrieved_docs, retrieved_metas)):\n",
    "                    st.markdown(f\"**Source {i+1}: {meta.get('title', 'N/A')}**\")\n",
    "                    st.caption(f\"URL: {meta.get('source_url', 'N/A')}\")\n",
    "                    st.text(doc)\n",
    "                    st.divider()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
